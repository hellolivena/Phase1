{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03360054-32e3-4fed-8ddb-2d3a044af0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #%%\n",
    "####################### Connect Python ##################\n",
    "import snowflake.connector as snow\n",
    "import pandas as pd\n",
    "user= 'ayush.pandey1-cw@otsuka-us.com'\n",
    "\n",
    "conn = snow.connect(\n",
    "            host='otsuka_ctprod.us-east-1.snowflakecomputing.com',\n",
    "            database='cdr',\n",
    "            user= user,\n",
    "            authenticator='externalbrowser',account='otsuka_ctprod.us-east-1',port=443)\n",
    "\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('USE DATABASE CDR')\n",
    "cursor.execute('USE SCHEMA operational_analytics')\n",
    "cursor.execute('USE WAREHOUSE OPA_MIG_M_WH')\n",
    "\n",
    "query = \"SELECT REGION_NAME,FRIDAY_END,SALES,CALLS FROM CT_TREND_MDD_FIELD_SALE_CALL where region_name=geo_name\"\n",
    "# query = \"SELECT * FROM RSC_DATES\"\n",
    "\n",
    "\n",
    "# Execute the query and load results into a Pandas DataFrame\n",
    "try:\n",
    "    weekly_sales_data= pd.read_sql(query, conn)\n",
    "    # Display the first 5 rows of the DataFrame\n",
    "finally:\n",
    "    conn.close()  \n",
    "\n",
    "#%%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import itertools\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "import threading\n",
    "from datetime import datetime\n",
    "import random\n",
    "#%%\n",
    "week_data_dist=weekly_sales_data\n",
    "week_data=weekly_sales_data\n",
    "\n",
    "#%%\n",
    "# Filter for TEAM and explicitly create a copy\n",
    "week_data = weekly_sales_data[weekly_sales_data['TEAM']=='MDD'].copy()\n",
    "\n",
    "# Convert 'FRIDAY_END' to datetime safely using .loc\n",
    "week_data.loc[:, 'FRIDAY_END'] = pd.to_datetime(week_data['FRIDAY_END'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "# Filter for matching REGION_NAME and GEO_NAME\n",
    "week_data = week_data[week_data['REGION_NAME'] == week_data['GEO_NAME']]\n",
    "\n",
    "# Sort the DataFrame\n",
    "week_data = week_data.sort_values(by=['TEAM', 'REGION_NAME', 'GEO_NAME', 'FRIDAY_END'])\n",
    "\n",
    "#%%\n",
    "def best_value_find(team,region_name,week_data):\n",
    "    global para_df\n",
    "    print(\"enter Region:\",team,region_name,datetime.now())\n",
    "    team_name=team\n",
    "    week_data_region=week_data\n",
    "    reg_name=region_name\n",
    "    # Check the size of the dataset\n",
    "    print(f\"Dataset size: {len(week_data_region)}\")\n",
    "    if week_data_region.empty:\n",
    "        raise ValueError(\"The dataset is empty for the given region and task.\")\n",
    "\n",
    "    # Split into test (latest 10 weeks) and train (remaining data)\n",
    "    test_df = week_data_region.tail(6)  # Latest 10 weeks\n",
    "    train_df = week_data_region.iloc[:-6]  # Rest of the data\n",
    "    \n",
    "    train_data = train_df['SALES']\n",
    "    train_data_calls=train_df['CALLS']\n",
    "    full_data=week_data_region['SALES']\n",
    "    full_data_calls=week_data_region['CALLS']\n",
    "    test_data = test_df['SALES']\n",
    "    test_data_calls=test_df['CALLS']\n",
    "    \n",
    "    \n",
    "    # Ignore all warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    # Define parameter ranges\n",
    "    p = range(1, 4)   # p: 0-4\n",
    "    d = range(0, 1)   # d: 0-1\n",
    "    q = range(1, 4)   # q: 0-4\n",
    "    P = range(0, 2)   # P: 0-3\n",
    "    D = range(0, 2)   # D: 0-1\n",
    "    Q = range(0, 2)   # Q: 0-3\n",
    "    m = 52            # Seasonal period (monthly data)\n",
    "    \n",
    "    # Create a list to store results\n",
    "    results = []\n",
    "    i = 1\n",
    "    print(\"b\")\n",
    "    # Loop through all parameter combinations\n",
    "    for (p_val, d_val, q_val, P_val, D_val, Q_val) in itertools.product(p, d, q, P, D, Q):\n",
    "        # print(\"R:\",reg_name,\"C:\",i)\n",
    "        print(\"R:\",reg_name,\"T:\",team,\"C:\",i,)\n",
    "        i += 1\n",
    "        try:\n",
    "            # Fit SARIMA model\n",
    "            model = SARIMAX(\n",
    "                train_data_calls,\n",
    "                order=(p_val, d_val, q_val),\n",
    "                seasonal_order=(P_val, D_val, Q_val, m),\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False,\n",
    "                # exog=train_data_calls\n",
    "            )\n",
    "            fitted_model = model.fit(disp=False)\n",
    "            forecast_values = fitted_model.forecast(steps=len(test_data_calls))\n",
    "            # Adjust the index of the forecast values to match the test data\n",
    "            forecast_values.index = test_data.index\n",
    "            \n",
    "            # Calculate evaluation metrics\n",
    "            mae = mean_absolute_error(test_data, forecast_values)\n",
    "            rmse = np.sqrt(mean_squared_error(test_data, forecast_values))\n",
    "            \n",
    "            # Max-Min Differences\n",
    "            max_min_actual = test_data.max() - test_data.min()\n",
    "            max_min_fitted = forecast_values.max() - forecast_values.min()\n",
    "        \n",
    "            # Calculate the count of same slope trends (i.e., compare differences between successive data points)\n",
    "            actual_diff = np.sign(np.diff(test_data))  # Sign of the difference between successive points\n",
    "            fitted_diff = np.sign(np.diff(forecast_values))  # Same for fitted values\n",
    "            same_slope_count = np.sum(actual_diff == fitted_diff)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'order': (p_val, d_val, q_val),\n",
    "                'seasonal_order': (P_val, D_val, Q_val, m),\n",
    "                'AIC': fitted_model.aic,\n",
    "                'MAE': mae,\n",
    "                'RMSE': rmse,\n",
    "                'Max-Min Actual': max_min_actual,\n",
    "                'Max-Min Fitted': max_min_fitted,\n",
    "                'Count Same Slope Trend': same_slope_count\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Handle any errors (e.g., convergence issues)\n",
    "            print(f\"Error for parameters: p={p_val}, d={d_val}, q={q_val}, P={P_val}, D={D_val}, Q={Q_val}, m={m}\")\n",
    "            print(str(e))\n",
    "    \n",
    "    # Convert results to DataFrame for better visualization\n",
    "    results_df= pd.DataFrame(results)\n",
    "    # print(3)\n",
    "    # print(\"Loop1:\",team,reg_name)\n",
    "    df=results_df[['order','seasonal_order','AIC','MAE','RMSE','Max-Min Fitted','Count Same Slope Trend']]\n",
    "    # df\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    # print(4)\n",
    "    \n",
    "    # Normalize columns to be minimized (AIC, MAE, RMSE, Max-Min Fitted)\n",
    "    df[['aic2_scaled', 'mse_scaled', 'rmse2_scaled', 'fitted_diff_scaled']] = min_max_scaler.fit_transform(df[['AIC', 'MAE', 'RMSE', 'Max-Min Fitted']])\n",
    "    \n",
    "    # Normalize the column to be maximized (Count Same Slope Trend) - we use max scaler to maximize it\n",
    "    df['count_scaled'] = max_scaler.fit_transform(df[['Count Same Slope Trend']])\n",
    "    # print(5)\n",
    "    \n",
    "    # Calculate a combined score. Minimized columns contribute negatively, maximized column contributes positively.\n",
    "    df['score'] = (\n",
    "    0.05 * df['aic2_scaled'] + 0.3* df['mse_scaled'] + 0.45 * df['rmse2_scaled'] + 0.2 * df['fitted_diff_scaled']-0.3*df['count_scaled'])\n",
    "    # df['score'] = (df['aic2_scaled'] + df['mse_scaled'] + df['rmse2_scaled'] + df['fitted_diff_scaled']) - df['count_scaled']\n",
    "    \n",
    "    # Sort the DataFrame by the score in ascending order (lowest score is best)\n",
    "    df_sorted = df.sort_values(by='score', ascending=True)\n",
    "    # print(6)\n",
    "    \n",
    "    # Select the top 5 most optimized rows (lowest scores)\n",
    "    best_value = df_sorted.head(1)\n",
    "    \n",
    "    # Output the top 5 most optimized rows\n",
    "    # best_value\n",
    "    # print(7)\n",
    "    # Convert the single row to a dictionary\n",
    "    row_dict = best_value.iloc[0].to_dict()\n",
    "    \n",
    "    # Extract p, d, q from 'order' and P, D, Q from 'seasonal_order'\n",
    "    order = row_dict['order']\n",
    "    seasonal_order = row_dict['seasonal_order']\n",
    "    \n",
    "    # Extract values from the tuples\n",
    "    p1, d1, q1 = order\n",
    "    P1, D1, Q1, m = seasonal_order  # m is not needed for extraction\n",
    "    \n",
    "    \n",
    "    model = SARIMAX(\n",
    "            full_data_calls,\n",
    "            order=(p1, d1, q1),\n",
    "            seasonal_order=(P1, D1, Q1, m),\n",
    "            enforce_stationarity=False,\n",
    "            enforce_invertibility=False,\n",
    "            # exog=train_data_calls\n",
    "        )\n",
    "    fitted_model = model.fit(disp=False)\n",
    "    Forecasted_calls = fitted_model.forecast(steps=12)\n",
    "    # print(8)\n",
    "    \n",
    "    # Assuming `forecast` is the array of predicted values\n",
    "    mean_data = (full_data_calls.mean())\n",
    "    max_data = (full_data_calls.max())\n",
    "    max_value=(max_data/mean_data)*1.1*mean_data\n",
    "    min_value= (mean_data/max_data)*0.8*mean_data\n",
    "    \n",
    "    # Clip the forecasted values\n",
    "    forecasted_calls = np.clip(Forecasted_calls, min_value, max_value)\n",
    "    \n",
    "    # Ignore all warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    # Define parameter ranges\n",
    "    p = range(1, 4)   # p: 0-4\n",
    "    d = range(0, 1)   # d: 0-1\n",
    "    q = range(1, 4)   # q: 0-4\n",
    "    P = range(0, 2)   # P: 0-3\n",
    "    D = range(0, 2)   # D: 0-1\n",
    "    Q = range(0, 2)   # Q: 0-3\n",
    "    m = 52            # Seasonal period (monthly data)\n",
    "    \n",
    "    # Create a list to store results\n",
    "    results = []\n",
    "    i = 1\n",
    "    # print(9)\n",
    "    \n",
    "    # Loop through all parameter combinations\n",
    "    for (p_val, d_val, q_val, P_val, D_val, Q_val) in itertools.product(p, d, q, P, D, Q):\n",
    "        print(\"R:\",reg_name,\"SC:\",i)\n",
    "        i += 1\n",
    "        \n",
    "        try:\n",
    "            # Fit SARIMA model\n",
    "            model = SARIMAX(\n",
    "                train_data,\n",
    "                order=(p_val, d_val, q_val),\n",
    "                seasonal_order=(P_val, D_val, Q_val, m),\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False,\n",
    "                exog=train_data_calls\n",
    "            )\n",
    "            fitted_model = model.fit(disp=False)\n",
    "            forecast_values = fitted_model.forecast(steps=len(test_data), exog=test_data_calls)\n",
    "            # Adjust the index of the forecast values to match the test data\n",
    "            forecast_values.index = test_data.index\n",
    "            \n",
    "            # Calculate evaluation metrics\n",
    "            mae = mean_absolute_error(test_data, forecast_values)\n",
    "            rmse = np.sqrt(mean_squared_error(test_data, forecast_values))\n",
    "            \n",
    "            # Max-Min Differences\n",
    "            max_min_actual = test_data.max() - test_data.min()\n",
    "            max_min_fitted = forecast_values.max() - forecast_values.min()\n",
    "        \n",
    "            # Calculate the count of same slope trends (i.e., compare differences between successive data points)\n",
    "            actual_diff = np.sign(np.diff(test_data))  # Sign of the difference between successive points\n",
    "            fitted_diff = np.sign(np.diff(forecast_values))  # Same for fitted values\n",
    "            same_slope_count = np.sum(actual_diff == fitted_diff)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'order': (p_val, d_val, q_val),\n",
    "                'seasonal_order': (P_val, D_val, Q_val, m),\n",
    "                'AIC': fitted_model.aic,\n",
    "                'MAE': mae,\n",
    "                'RMSE': rmse,\n",
    "                'Max-Min Actual': max_min_actual,\n",
    "                'Max-Min Fitted': max_min_fitted,\n",
    "                'Count Same Slope Trend': same_slope_count\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Handle any errors (e.g., convergence issues)\n",
    "            print(f\"Error for parameters: p={p_val}, d={d_val}, q={q_val}, P={P_val}, D={D_val}, Q={Q_val}, m={m}\")\n",
    "            print(str(e))\n",
    "    # print(10)\n",
    "    \n",
    "    # Convert results to DataFrame for better visualization\n",
    "    results_df_2 = pd.DataFrame(results)\n",
    "    df=results_df_2[['order','seasonal_order','AIC','MAE','RMSE','Max-Min Fitted','Count Same Slope Trend']]\n",
    "    # df\n",
    "        \n",
    "    # Initialize scalers\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "    # Normalize columns to be minimized (AIC, MAE, RMSE, Max-Min Fitted)\n",
    "    df[['aic2_scaled', 'mse_scaled', 'rmse2_scaled', 'fitted_diff_scaled']] = min_max_scaler.fit_transform(df[['AIC', 'MAE', 'RMSE', 'Max-Min Fitted']])\n",
    "    \n",
    "    # Normalize the column to be maximized (Count Same Slope Trend) - we use max scaler to maximize it\n",
    "    df['count_scaled'] = max_scaler.fit_transform(df[['Count Same Slope Trend']])\n",
    "    \n",
    "    # Calculate a combined score. Minimized columns contribute negatively, maximized column contributes positively.\n",
    "    df['score'] = (\n",
    "    0.05 * df['aic2_scaled'] + 0.3* df['mse_scaled'] + 0.45 * df['rmse2_scaled'] + 0.2 * df['fitted_diff_scaled']-0.3*df['count_scaled'])\n",
    "    # df['score'] = (df['aic2_scaled'] + df['mse_scaled'] + df['rmse2_scaled'] + df['fitted_diff_scaled']) - df['count_scaled']\n",
    "    \n",
    "    # Sort the DataFrame by the score in ascending order (lowest score is best)\n",
    "    df_sorted = df.sort_values(by='score', ascending=True)\n",
    "    \n",
    "    # Select the top 5 most optimized rows (lowest scores)\n",
    "    best_value_2 = df_sorted.head(1)\n",
    "    # print(11)\n",
    "    # Convert the single row to a dictionary\n",
    "    row_dict = best_value_2.iloc[0].to_dict()\n",
    "    # print(\"Loop2:\",team,reg_name)\n",
    "    # Extract p, d, q from 'order' and P, D, Q from 'seasonal_order'\n",
    "    order = row_dict['order']\n",
    "    seasonal_order = row_dict['seasonal_order']\n",
    "    # print(12)\n",
    "    # Extract values from the tuples\n",
    "    p2, d2, q2 = order\n",
    "    P2, D2, Q2, m = seasonal_order  # m is not needed for extraction\n",
    "    \n",
    "    para_reg=[team_name,reg_name,p1,d1,q1,P1,D1,Q1,p2,d2,q2,P2,D2,Q2]\n",
    "    para_reg_df = pd.DataFrame([para_reg], columns=['team','reg_name','p1','d1','q1','P1','D1','Q1','p2','d2','q2','P2','D2','Q2'])\n",
    "    para_df = pd.concat([para_df, result], ignore_index=True)\n",
    "    return para_reg_df\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "para_col=['team','reg_name','p1','d1','q1','P1','D1','Q1','p2','d2','q2','P2','D2','Q2']\n",
    "para_df=pd.DataFrame(columns=para_col)\n",
    "\n",
    "\n",
    "# Start threads for each region\n",
    "for team, region in week_data[['TEAM', 'REGION_NAME']].drop_duplicates().values:\n",
    "        region_data = week_data[(week_data['REGION_NAME'] == region) & (week_data['TEAM'] == team)]\n",
    "        best_value_find(team,region,region_data)\n",
    "        \n",
    "\n",
    "print(\"Final DataFrame:\")\n",
    "print(para_df)\n",
    "\n",
    "final_df=para_df\n",
    "\n",
    "#%%\n",
    "final_df.to_csv('best_arima_para_mdd.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
